{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "293e49ed",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-03T07:38:53.316833Z",
     "start_time": "2022-09-03T07:38:53.223790Z"
    }
   },
   "outputs": [],
   "source": [
    "import os.path as path   \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "dt_format = '%H:%M:%S,%d-%m-%Y'\n",
    "sep = ','\n",
    "\n",
    "trips_cols = [\n",
    "              'trip_id',\n",
    "              'driver_id',\n",
    "              'pickup_datetime',\n",
    "              'dropoff_datetime',\n",
    "              'passenger_count',\n",
    "              'pickup_loc_id',\n",
    "              'dropoff_loc_id',\n",
    "              'trip_distance',\n",
    "              'fare_amount'\n",
    "             ]\n",
    "drivers_cols = [\n",
    "                'driver_id',\n",
    "                'last_name',\n",
    "                'given_name'\n",
    "              ]\n",
    "locs_cols = [\n",
    "            'location_id',\n",
    "            'loc_name'\n",
    "           ]\n",
    "trips_dtypes = {\n",
    "                'trip_id': int,\n",
    "                'driver_id': int,\n",
    "                'pickup_datetime': 'datetime64[ns]',\n",
    "                'dropoff_datetime': 'datetime64[ns]',\n",
    "                'passenger_count': int,\n",
    "                'pickup_loc_id': int,\n",
    "                'dropoff_loc_id': int,\n",
    "                'trip_distance': float,\n",
    "                'fare_amount': float\n",
    "               }\n",
    "drivers_dtypes = {\n",
    "                  'driver_id': int,\n",
    "                  'last_name': str,\n",
    "                  'given_name': str\n",
    "                }\n",
    "locs_dtypes = {\n",
    "              'location_id': int,\n",
    "              'loc_name': str\n",
    "              }\n",
    "\n",
    "# Loraine: Had to create a separate data type and date column references\n",
    "# since the current would not work when reading files\n",
    "dow_order = {'Monday': 0, 'Tuesday': 1, 'Wednesday': 2, 'Thursday': 3, \n",
    "            'Friday': 4, 'Saturday': 5, 'Sunday': 6}\n",
    "\n",
    "trips_dates = ['pickup_datetime', 'dropoff_datetime']\n",
    "trips_dtypes_read = {\n",
    "                'trip_id': int,\n",
    "                'driver_id': int,\n",
    "                'passenger_count': int,\n",
    "                'pickup_loc_id': int,\n",
    "                'dropoff_loc_id': int,\n",
    "                'trip_distance': float,\n",
    "                'fare_amount': float\n",
    "               }\n",
    "\n",
    "\n",
    "def check_driver(driver):\n",
    "        \n",
    "        special_characters = '''!\\\"#$%&'()*+-/:;<=>?@[\\]^_`{|}~'''\n",
    "        if type(driver) is not str or driver.strip() == '': \n",
    "            return 'Name should not be empty or must be in string format'\n",
    "        if len(driver.split(',')) != 2:\n",
    "            return 'Invalid name format should be (First Name, Last Name)'\n",
    "        if any(c in special_characters for c in driver):\n",
    "            return 'Name contains special characters'\n",
    "        return None\n",
    "\n",
    "\n",
    "def check_dt(dt, dt_col): \n",
    "    \n",
    "    if type(dt) is not str: \n",
    "        return (f'{dt_col} should be in string format')\n",
    "    if pd.isnull(pd.to_datetime(dt.strip(), format=dt_format, errors='coerce')): \n",
    "        return (f'{dt_col} should be in valid format')\n",
    "    return None\n",
    "\n",
    "\n",
    "def check_pass_cnt(cnt):\n",
    " \n",
    "    if type(cnt) is not int: \n",
    "        return 'Passenger count should be integer value'\n",
    "    if cnt < 0:\n",
    "        return 'Passenger count should be a positive value >= 0'\n",
    "    return None\n",
    "\n",
    "\n",
    "def check_loc(loc, loc_col):\n",
    "\n",
    "    special_characters = '''!\\\"%&'()+-/:;<=>?@[\\]^_`{|}~'''\n",
    "    if type(loc) is not str or loc.strip() == '': \n",
    "        return(f'{loc_col} should not be empty or must be in string format')   \n",
    "    elif any(c in special_characters for c in loc):\n",
    "            return 'Location contains special characters'\n",
    "    return None\n",
    "\n",
    "\n",
    "def check_trip_d(val):\n",
    "    \n",
    "    if type(val) is not float and type(val) is not int:\n",
    "        return 'Trip Distance should be a numeric value'\n",
    "    if val < 0:\n",
    "        return 'Trip Distance should be a positive number'\n",
    "    return None\n",
    "\n",
    "\n",
    "def check_fare(val):\n",
    "    \n",
    "    if type(val) is not float and type(val) is not int:\n",
    "        return 'Fare Amount should be a numeric value'\n",
    "    if val < 0:\n",
    "        return 'Fare Amount should be a positive number'\n",
    "    return None\n",
    "\n",
    "def check_start_end(p_dt, d_dt):\n",
    "    p_dt = pd.to_datetime(p_dt.strip(), format=dt_format, errors='coerce')\n",
    "    d_dt = pd.to_datetime(d_dt.strip(), format=dt_format, errors='coerce')\n",
    "\n",
    "    if (p_dt > d_dt):\n",
    "        return 'Pickup Date Time should be lower than Dropoff Date Time'\n",
    "    return None\n",
    " \n",
    "\n",
    "def add_trip_checks(param_list):\n",
    "    lst_validator = [check_driver, check_dt, check_dt,\n",
    "                     check_pass_cnt, check_loc, check_loc,\n",
    "                     check_trip_d, check_fare, check_start_end]\n",
    "\n",
    "    for key, func in enumerate(lst_validator):\n",
    "        if key == 1:\n",
    "            chk = func(param_list[key], 'Pickup Date Time')\n",
    "        elif key == 2:\n",
    "            chk = func(param_list[key], 'Dropoff Date Time')\n",
    "        elif key == 4:\n",
    "            chk = func(param_list[key], 'Pickup Location')\n",
    "        elif key == 5:\n",
    "            chk = func(param_list[key], 'Dropoff Location')\n",
    "        elif key == 8:\n",
    "            chk = func(param_list[1] ,param_list[2])\n",
    "        else:\n",
    "            chk = func(param_list[key])\n",
    "        if chk is not None:\n",
    "            return chk\n",
    "        \n",
    "def create_file(dir, cols):\n",
    "    \n",
    "    df = pd.DataFrame(columns=cols)\n",
    "    df.to_csv(dir, sep=sep, header=True, index=False)\n",
    "    return None\n",
    "\n",
    "\n",
    "def check_driver_id(name, f_dir):\n",
    "    \n",
    "    df = pd.read_csv(f_dir, sep=sep)\n",
    "    df.given_name = df.given_name.str.lower()\n",
    "    df.last_name = df.last_name.str.lower()\n",
    "\n",
    "    df_res = df.query('last_name==@name[0].lower() & given_name==@name[1].lower()')\n",
    "    \n",
    "    if len(df_res) == 0:\n",
    "        last_val = df.tail(1)\n",
    "        if len(last_val) == 1:\n",
    "            return last_val.driver_id.values[0]+1, True\n",
    "        return 1, True\n",
    "    else:\n",
    "        return df_res.driver_id.values[0], False\n",
    "    \n",
    "    \n",
    "def check_loc_id(loc, f_dir):\n",
    "  \n",
    "    df = pd.read_csv(f_dir, sep=sep)\n",
    "    df_res = df.query('loc_name==@loc')\n",
    "    \n",
    "    if len(df_res) == 0:\n",
    "        last_val = df.tail(1)\n",
    "        if len(last_val) == 1:\n",
    "            return last_val.location_id.values[0]+1, True\n",
    "        return 1, True\n",
    "    else:\n",
    "        return df_res.location_id.values[0], False\n",
    "    \n",
    "def check_trip_id(data, f_dir):\n",
    "\n",
    "    df = pd.read_csv(f_dir, sep=sep)\n",
    "    df_res = df.query('driver_id == @data[0]'\n",
    "                   '& pickup_datetime == @data[1]'\n",
    "                   '& dropoff_datetime == @data[2]'\n",
    "                   '& passenger_count == @data[3]'\n",
    "                   '& pickup_loc_id == @data[4]'\n",
    "                   '& dropoff_loc_id == @data[5]' \n",
    "                   '& trip_distance == @data[6]'\n",
    "                   '& fare_amount == @data[7]')\n",
    "    \n",
    "    if len(df_res) == 0:\n",
    "        last_val = df.tail(1)\n",
    "        if len(last_val) == 1:\n",
    "            return last_val.trip_id.values[0]+1, False\n",
    "        return 1, False\n",
    "    else:\n",
    "        return 0, True\n",
    "\n",
    "\n",
    "def insert_data(data, file_p, cols_lst):\n",
    "    insert_df = pd.DataFrame(data, columns=cols_lst)\n",
    "    insert_df.to_csv(file_p, mode='a', index=False, header=False, sep=sep)\n",
    "    return None\n",
    "\n",
    "def del_trip(trip_id, f_dir):\n",
    " \n",
    "    df = pd.read_csv(f_dir, sep=sep)\n",
    "    df_res = df.query('trip_id != @trip_id')\n",
    "\n",
    "    if len(df) == len(df_res):\n",
    "        return False\n",
    "    else:\n",
    "        df_res.to_csv(f_dir, sep=sep, header=True, index=False)\n",
    "        return True\n",
    "     \n",
    "    \n",
    "# Loraine: Added a function for reading the csv files.\n",
    "# Feel free to use this if needed\n",
    "def read_data(dataset, fname):\n",
    "    if dataset == 'trips':\n",
    "        return (pd.read_csv(fname, dtype=trips_dtypes_read,\n",
    "                 parse_dates=trips_dates,\n",
    "                 date_parser= lambda x: pd.to_datetime(x, format=dt_format)))\n",
    "    elif dataset == 'drivers':\n",
    "        return (pd.read_csv(fname, dtype=drivers_dtypes,\n",
    "                 date_parser= lambda x: pd.to_datetime(x, format=dt_format)))\n",
    "    elif dataset == 'locations':\n",
    "        return (pd.read_csv(fname, dtype=locs_dtypes,\n",
    "                 date_parser= lambda x: pd.to_datetime(x, format=dt_format)))\n",
    "    else:\n",
    "        raise SakayDBError(\"Request dataset not found. Choose among 'trips', \\\n",
    "                           'drivers', or 'locations'\")\n",
    "      \n",
    "      \n",
    "        \n",
    "class SakayDBError(ValueError):\n",
    "    \n",
    "    def __init__(self, message):\n",
    "        self.message = 'Error encountered: ' + str(message)\n",
    "        super().__init__(self.message)\n",
    "\n",
    "\n",
    "\n",
    "class SakayDB:\n",
    "        \n",
    "    def __init__(self, f_dir):\n",
    "        if path.exists(f_dir) == False:\n",
    "            raise SakayDBError(f'Directory {f_dir} does not exist')\n",
    "            \n",
    "        self.data_dir = f_dir\n",
    "        self.__trips_dir = path.join(f_dir, 'trips.csv')\n",
    "        self.__drivers_dir = path.join(f_dir, 'drivers.csv')\n",
    "        self.__locs_dir = path.join(f_dir, 'locations.csv')\n",
    "        \n",
    "        if path.exists(self.__trips_dir) == False:\n",
    "            create_file(self.__trips_dir, trips_cols)\n",
    "            \n",
    "        if path.exists(self.__drivers_dir) == False:\n",
    "            create_file(self.__drivers_dir, drivers_cols)\n",
    "            \n",
    "        if path.exists(self.__locs_dir) == False:\n",
    "            create_file(self.__locs_dir, locs_cols)\n",
    "        \n",
    "        \n",
    "    def add_trip(self, driver, pickup_datetime, dropoff_datetime, passenger_count,\n",
    "                 pickup_loc_name, dropoff_loc_name, trip_distance, fare_amount, is_trips=None):\n",
    "        \n",
    "        param_lst = [driver, pickup_datetime, dropoff_datetime, passenger_count,\n",
    "                     pickup_loc_name, dropoff_loc_name, trip_distance, fare_amount]\n",
    "        \n",
    "        chk = add_trip_checks(param_lst)\n",
    "        \n",
    "        if chk is not None:\n",
    "            if is_trips is None:\n",
    "                raise SakayDBError(chk)\n",
    "            else:\n",
    "                print(f'Warning: trip index {is_trips} has invalid or incomplete information. Skipping...')\n",
    "                return None\n",
    "            \n",
    "        split_name = [x.strip() for x in driver.split(',')]\n",
    "        driver_id, is_new_driver = check_driver_id(split_name, self.__drivers_dir)\n",
    "        \n",
    "        pickup_loc_name = pickup_loc_name.strip()\n",
    "        dropoff_loc_name = dropoff_loc_name.strip()\n",
    "        \n",
    "        p_loc_id, is_new_p_loc = check_loc_id(pickup_loc_name, self.__locs_dir)\n",
    "        d_loc_id, is_new_d_loc = check_loc_id(dropoff_loc_name, self.__locs_dir)\n",
    "        \n",
    "        param_lst[0] = driver_id\n",
    "        param_lst[4] = p_loc_id\n",
    "        \n",
    "        if is_new_p_loc and is_new_d_loc:\n",
    "                d_loc_id += 1\n",
    "        \n",
    "        param_lst[5] = d_loc_id\n",
    "        \n",
    "        trip_id, is_dup = check_trip_id(param_lst, self.__trips_dir)\n",
    "    \n",
    "        if is_dup:\n",
    "            if is_trips is None:\n",
    "                raise SakayDBError('Duplicate Trip Entry')\n",
    "            else:\n",
    "                print(f'Warning: trip index {is_trips} is already in the database. Skipping...')\n",
    "                return None\n",
    "            \n",
    "        if is_new_driver:\n",
    "            driver_data = [[driver_id, split_name[0], split_name[1]]]\n",
    "            insert_data(driver_data, self.__drivers_dir, drivers_dtypes)\n",
    "            \n",
    "        if is_new_p_loc:\n",
    "            loc_data = [[p_loc_id, pickup_loc_name]]\n",
    "            insert_data(loc_data, self.__locs_dir, locs_dtypes)\n",
    "            \n",
    "            \n",
    "        if is_new_d_loc:\n",
    "            loc_data = [[d_loc_id, dropoff_loc_name]]\n",
    "            insert_data(loc_data, self.__locs_dir, locs_dtypes)\n",
    "\n",
    "        \n",
    "        trip_data = [[\n",
    "                      trip_id,\n",
    "                      param_lst[0],\n",
    "                      param_lst[1],\n",
    "                      param_lst[2],\n",
    "                      param_lst[3],\n",
    "                      param_lst[4], \n",
    "                      param_lst[5],\n",
    "                      param_lst[6],\n",
    "                      param_lst[7]\n",
    "                    ]]\n",
    "            \n",
    "        insert_data(trip_data, self.__trips_dir, trips_dtypes)\n",
    "        \n",
    "        return trip_id\n",
    "    \n",
    "    \n",
    "    def add_trips(self, trip_list):\n",
    "        \n",
    "        if type(trip_list) is not list:\n",
    "            raise SakayDBError('Trips should be a valid list')\n",
    "        \n",
    "        for i, val in enumerate(trip_list):\n",
    "            self.add_trip(val.get('driver'),\n",
    "                          val.get('pickup_datetime'),\n",
    "                          val.get('dropoff_datetime'),\n",
    "                          val.get('passenger_count'),\n",
    "                          val.get('pickup_loc_name'),\n",
    "                          val.get('dropoff_loc_name'),\n",
    "                          val.get('trip_distance'),\n",
    "                          val.get('fare_amount'),\n",
    "                          i)\n",
    "        \n",
    "        \n",
    "    def delete_trip(self, trip_id):\n",
    "        \n",
    "        if type(trip_id) is not int:\n",
    "            raise SakayDBError('Trip ID should be integer value')\n",
    "        \n",
    "        if del_trip(trip_id, self.__trips_dir) == False:\n",
    "            raise SakayDBError('Trip ID not found')\n",
    "\n",
    "    def generate_statistics(self, stat, df=None):\n",
    "        \"\"\"\n",
    "        Return a dictionary depending on the `stat` parameter passed to it\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        stat : str\n",
    "            Statistics to be generated. Can be details of the trip, passenger,\n",
    "            driver, or all of the above\n",
    "        df : pandas dataframe\n",
    "            Dataframe to be used for creating the statistics.\n",
    "            Uses the `trips` and `drivers` database by default.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        generate_statistics : dict\n",
    "            Dictionary containing the statistics requested based on `stat`\n",
    "            parameter\n",
    "        \"\"\"\n",
    "        # if df is None, use default dfs, else use input param\n",
    "        if stat == 'trip':\n",
    "            if df is None:\n",
    "                df_trips = read_data('trips', self.__trips_dir)\n",
    "                if len(df_trips) == 0:\n",
    "                    return {}\n",
    "                else:\n",
    "                    dow = df_trips.pickup_datetime.dt.strftime('%A')\n",
    "                    return ((df_trips.groupby(dow).trip_id.nunique() /\n",
    "                             df_trips.groupby(dow).pickup_datetime\n",
    "                                 .apply(lambda x: x.dt.date.nunique()))\n",
    "                                 .sort_index(key=lambda x: x.map(dow_order))\n",
    "                                 .to_dict())\n",
    "\n",
    "            else:\n",
    "                dow = df.pickup_datetime.dt.strftime('%A')\n",
    "                return ((df.groupby(dow).trip_id.nunique() /\n",
    "                         df.groupby(dow).pickup_datetime\n",
    "                           .apply(lambda x: x.dt.date.nunique()))\n",
    "                           .sort_index(key=lambda x: x.map(dow_order))\n",
    "                           .to_dict())\n",
    "\n",
    "        elif stat == 'passenger':\n",
    "            df_trips = read_data('trips', self.__trips_dir)\n",
    "            if len(df_trips) == 0:\n",
    "                return {}\n",
    "            else:\n",
    "                return {k: self.generate_statistics('trip', v)\n",
    "                        for k, v in df_trips.groupby('passenger_count')}\n",
    "\n",
    "        elif stat == 'driver':\n",
    "            df_drivers = read_data('drivers', self.__drivers_dir)\n",
    "            df_trips = read_data('trips', self.__trips_dir)\n",
    "            if (len(df_drivers) == 0) | (len(df_trips) == 0):\n",
    "                return {}\n",
    "            else:\n",
    "                df_temp = (df_drivers.merge(df_trips[['driver_id', 'trip_id',\n",
    "                            'pickup_datetime']], how='left', on='driver_id'))\n",
    "                df_temp['driver_name'] = (df_temp[['last_name', 'given_name']]\n",
    "                                             .apply(lambda x: ', '.join(x),\n",
    "                                             axis=1))\n",
    "                return {k: self.generate_statistics('trip', v)\n",
    "                        for k, v in df_temp.groupby('driver_name')}\n",
    "\n",
    "        elif stat == 'all':\n",
    "            return {'trip': self.generate_statistics('trip'),\n",
    "                    'passenger': self.generate_statistics('passenger'),\n",
    "                    'driver': self.generate_statistics('driver')}\n",
    "\n",
    "        else:\n",
    "            raise SakayDBError('Input parameter is unknown.')\n",
    "\n",
    "    def search_trips(self, **kwargs):\n",
    "        df = read_data('trips', self.__trips_dir)\n",
    "        col_list = df.columns.tolist()\n",
    "        if kwargs == {}:\n",
    "            raise SakayDBError('Invalid keyword')\n",
    "        else:\n",
    "            if len(df) == 0:\n",
    "                return []\n",
    "            else:\n",
    "                for i, j in kwargs.items():\n",
    "                    if i in col_list:\n",
    "                        if type(j) is not tuple and type(j) is int:\n",
    "                            df = df.loc[df[i] == j]\n",
    "                        elif (type(j) is tuple) and (len(j) == 2):\n",
    "                            if (all(isinstance(n, str) for n in j) is True):\n",
    "                                df['pickup_datetime_1'] = pd.to_datetime(df[i],\n",
    "                                                                format='%H:%M:%S,%d-%m-%Y')\n",
    "                                df['dropoff_datetime_2'] = pd.to_datetime(df[i],\n",
    "                                                                format='%H:%M:%S,%d-%m-%Y')\n",
    "                                a = pd.to_datetime(j[0], format='%H:%M:%S,%d-%m-%Y')\n",
    "                                b = pd.to_datetime(j[1], format='%H:%M:%S,%d-%m-%Y')\n",
    "                                if (j[0] is not None) and (j[1] is not None) and (a <= b):\n",
    "                                    df = df.loc[(df[i+'_1'] >= a) & (df[i+'_1'] <= b)]\n",
    "                                    df = df.iloc[:,:-2]\n",
    "                                elif (j[0] is None) and (j[1] is not None):\n",
    "                                    df = df.loc[df[i+'_1'] <= b]\n",
    "                                    df = df.iloc[:,:-2]\n",
    "                                elif (j[0] is not None) and (j[1] is None):\n",
    "                                    df = df.loc[df[i+'_1'] >= a]\n",
    "                                    df = df.iloc[:,:-2]\n",
    "                                else:\n",
    "                                    raise SakayDBError('Invalid values for range')\n",
    "                            elif (all(isinstance(n, str) for n in j) is False):\n",
    "                                if (j[0] is not None) and (j[1] is not None) and (j[0] <= j[1]):\n",
    "                                    df = df.loc[(df[i] >= j[0]) & (df[i] <= j[1])]\n",
    "                                elif (j[0] is None) and (j[1] is not None):\n",
    "                                    df = df.loc[df[i] <= j[1]]\n",
    "                                elif (j[0] is not None) and (j[1] is None):\n",
    "                                    df = df.loc[df[i] >= j[0]]\n",
    "                                else:\n",
    "                                    raise SakayDBError('Invalid values for range')\n",
    "                        else:\n",
    "                            raise SakayDBError('Invalid values for range')\n",
    "                    else:\n",
    "                        raise SakayDBError('Invalid keyword')\n",
    "                    df = df.sort_values(by=i)\n",
    "                df['pickup_datetime'] = df['pickup_datetime'].dt.strftime(dt_format)    \n",
    "                df['dropoff_datetime'] = df['dropoff_datetime'].dt.strftime(dt_format)\n",
    "                return df\n",
    "            \n",
    "    def generate_odmatrix(self, date_range=None):\n",
    "        df_trips = read_data('trips', self.__trips_dir)\n",
    "        df_loc = pd.read_csv('locations.csv')\n",
    "        \n",
    "        if len(df_trips) == 0:\n",
    "            return df_trips\n",
    "        else:\n",
    "            pass\n",
    "        df = df_trips.merge(df_loc,\n",
    "                    left_on='pickup_loc_id',\n",
    "                    right_on='location_id',\n",
    "                    how='left')\n",
    "        df = df.merge(df_loc,\n",
    "                      left_on='dropoff_loc_id',\n",
    "                      right_on='location_id',\n",
    "                      how='left')\n",
    "        df['pickup_datetime_1'] = pd.to_datetime(df['pickup_datetime'],\n",
    "                                                 format='%H:%M:%S,%d-%m-%Y')\n",
    "        df['count'] = 1\n",
    "        col_dict = {'loc_name_x': 'pickup_loc_name',\n",
    "                    'loc_name_y': 'dropoff_loc_name'}\n",
    "        df.rename(columns=col_dict, inplace=True)\n",
    "        case = 0\n",
    "        filt = 'pickup_datetime_1'\n",
    "\n",
    "        if date_range == None:\n",
    "            case = 0\n",
    "        elif (date_range != None):\n",
    "            if (type(date_range) is not tuple):\n",
    "                raise SakayDBError('Invalid values for range')\n",
    "            elif (type(date_range) is tuple) and (len(date_range) != 2):\n",
    "                raise SakayDBError('Invalid values for range')\n",
    "            elif (type(date_range) is tuple) and (len(date_range) == 2):\n",
    "                if (date_range[0] is not None) and \\\n",
    "                   (date_range[1] is not None):\n",
    "                    date_1 = pd.to_datetime(date_range[0],\n",
    "                                            format='%H:%M:%S,%d-%m-%Y')\n",
    "                    date_2 = pd.to_datetime(date_range[1],\n",
    "                                            format='%H:%M:%S,%d-%m-%Y')\n",
    "                    if date_1 > date_2:\n",
    "                        raise SakayDBError('Invalid values for range')\n",
    "                    elif date_1 <= date_2:\n",
    "                        case = 1\n",
    "                elif (date_range[0] is None) and (date_range[1] is not None):\n",
    "                    case = 2\n",
    "                elif (date_range[0] is not None) and (date_range[1] is None):\n",
    "                    case = 3\n",
    "\n",
    "        if case == 0:\n",
    "            df = df\n",
    "        elif case != 1:\n",
    "            start_date = pd.to_datetime(date_range[0],\n",
    "                                        format='%H:%M:%S,%d-%m-%Y')\n",
    "            end_date = pd.to_datetime(date_range[1],\n",
    "                                      format='%H:%M:%S,%d-%m-%Y')\n",
    "            if case == 1:\n",
    "                df = df.loc[(df[filt] >= start_date) & (df[filt] <= end_date)]\n",
    "            elif case == 2:\n",
    "                df = df.loc[df[filt] <= end_date]\n",
    "            elif case == 3:\n",
    "                df = df.loc[df[filt] >= start_date]\n",
    "        df = df.sort_values(by=filt)\n",
    "        df = df.groupby(['pickup_loc_name',\n",
    "                         'dropoff_loc_name',\n",
    "                         pd.Grouper(key='pickup_datetime_1',\n",
    "                                    freq='D')]).sum().reset_index()\n",
    "        df = df.pivot_table(values='count',\n",
    "                            index='dropoff_loc_name',\n",
    "                            columns='pickup_loc_name',\n",
    "                            aggfunc='mean',\n",
    "                            fill_value=0)\n",
    "        return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acaa8414",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-02T09:05:30.102941Z",
     "start_time": "2022-09-02T09:05:30.091286Z"
    }
   },
   "source": [
    "# Asserts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "2aec6626",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-03T07:38:54.883540Z",
     "start_time": "2022-09-03T07:38:54.875526Z"
    }
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import shutil\n",
    "import os\n",
    "import pandas as pd\n",
    "from tempfile import TemporaryDirectory\n",
    "from numpy.testing import (assert_equal, assert_almost_equal,\n",
    "                           assert_raises, assert_allclose)\n",
    "sakay_db = SakayDB('.')\n",
    "assert_equal(sakay_db.data_dir, '.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "a14ff0d3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-03T07:38:55.995303Z",
     "start_time": "2022-09-03T07:38:55.621056Z"
    }
   },
   "outputs": [],
   "source": [
    "trip_columns = ['trip_id', 'driver_id', 'pickup_datetime', 'dropoff_datetime',\n",
    "                'passenger_count', 'pickup_loc_id', 'dropoff_loc_id',\n",
    "                'trip_distance', 'fare_amount']\n",
    "driver_columns = ['driver_id', 'given_name', 'last_name']\n",
    "with TemporaryDirectory() as temp_dir:\n",
    "    sakay_db = SakayDB(temp_dir)\n",
    "    shutil.copy('locations.csv', os.path.join(temp_dir, 'locations.csv'))\n",
    "    assert_equal(\n",
    "        sakay_db.add_trip('Dailisan, Damian', '08:13:00,15-05-2022',\n",
    "                          '08:46:00,15-05-2022', 2,\n",
    "                          'UP Campus', 'Legazpi Village', 17.6, 412),\n",
    "        1\n",
    "    )\n",
    "    assert_raises(\n",
    "        SakayDBError,\n",
    "        lambda: sakay_db.add_trip('Dailisan, Damian', '08:13:00,15-05-2022',\n",
    "                                  '08:46:00,15-05-2022', 2, 'UP Campus',\n",
    "                                  'Legazpi Village', 17.6, 412)\n",
    "    )\n",
    "    df_trips = pd.read_csv(os.path.join(temp_dir, 'trips.csv'))\n",
    "    assert_equal(\n",
    "        set(df_trips.columns.tolist()),\n",
    "        set(trip_columns)\n",
    "    )\n",
    "    assert_equal(\n",
    "        df_trips.to_numpy().tolist(),\n",
    "        [[1, 1, '08:13:00,15-05-2022',\n",
    "          '08:46:00,15-05-2022',\n",
    "          2, 1, 2, 17.6, 412]]\n",
    "    )\n",
    "    assert_equal(\n",
    "        df_trips.index.tolist(),\n",
    "        [0]\n",
    "    )\n",
    "    df_drivers = pd.read_csv(os.path.join(temp_dir, 'drivers.csv'))\n",
    "    assert_equal(\n",
    "        set(df_drivers.columns.tolist()),\n",
    "        set(driver_columns)\n",
    "    )\n",
    "    assert_equal(\n",
    "        df_drivers[driver_columns].to_numpy().tolist(),\n",
    "        [[1, 'Damian', 'Dailisan']]\n",
    "    )\n",
    "    assert_equal(\n",
    "        df_drivers.index.tolist(),\n",
    "        [0]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "97fc3fad",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-03T07:38:56.927986Z",
     "start_time": "2022-09-03T07:38:56.249597Z"
    }
   },
   "outputs": [],
   "source": [
    "with TemporaryDirectory() as temp_dir:\n",
    "    sakay_db = SakayDB(temp_dir)\n",
    "    shutil.copy('locations.csv', os.path.join(temp_dir, 'locations.csv'))\n",
    "    assert_equal(\n",
    "        sakay_db.add_trip('Dailisan, Damian', '08:13:00,15-05-2022',\n",
    "                          '08:46:00,15-05-2022', 2,\n",
    "                          'UP Campus', 'Legazpi Village', 17.6, 412),\n",
    "        1\n",
    "    )\n",
    "    assert_equal(\n",
    "        sakay_db.add_trip('Dorosan, Michael', '14:13:00,31-12-2022',\n",
    "                          '14:46:00,31-12-2022', 1,\n",
    "                          'Fairview', 'Highway Hills', 15.1, 371),\n",
    "        2\n",
    "    )\n",
    "    assert_equal(\n",
    "        sakay_db.add_trip('Alis, Christian', '09:13:00,16-08-2022',\n",
    "                          '09:46:00,16-08-2022', 3,\n",
    "                          'Loyola Heights', 'Legazpi Village', 8.9, 235),\n",
    "        3\n",
    "    )\n",
    "    assert_equal(\n",
    "        sakay_db.add_trip('Dailisan, Damian', '15:13:00,09-09-2022',\n",
    "                          '15:46:00,09-09-2022', 2,\n",
    "                          'Pasong Putik', 'San Antonio', 31.2, 716),\n",
    "        4\n",
    "    )\n",
    "    assert_raises(\n",
    "        SakayDBError,\n",
    "        lambda: sakay_db.add_trip('Alis, Christian', '09:13:00,16-08-2022',\n",
    "                                  '09:46:00,16-08-2022', 3,\n",
    "                                  'Loyola Heights', 'Legazpi Village', 8.9, 235)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "8c433e77",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-03T07:38:57.868389Z",
     "start_time": "2022-09-03T07:38:57.311476Z"
    }
   },
   "outputs": [],
   "source": [
    "with TemporaryDirectory() as temp_dir:\n",
    "    sakay_db = SakayDB(temp_dir)\n",
    "    shutil.copy('locations.csv', os.path.join(temp_dir, 'locations.csv'))\n",
    "    assert_equal(\n",
    "        sakay_db.add_trip('Dailisan, Damian', '08:13:00,15-05-2022',\n",
    "                          '08:46:00,15-05-2022', 2,\n",
    "                          'UP Campus', 'Legazpi Village', 17.6, 412),\n",
    "        1\n",
    "    )\n",
    "    assert_equal(\n",
    "        sakay_db.add_trip('Dailisan, Damian', '14:13:00,31-12-2022',\n",
    "                          '14:46:00,31-12-2022', 1,\n",
    "                          'Fairview', 'Highway Hills', 15.1, 371),\n",
    "        2\n",
    "    )\n",
    "    assert_equal(\n",
    "        sakay_db.add_trip('Dailisan, Damian', '09:13:00,16-08-2022',\n",
    "                          '09:46:00,16-08-2022', 3,\n",
    "                          'Fairview', 'Highway Hills', 17.6, 412),\n",
    "        3\n",
    "    )\n",
    "    assert_raises(\n",
    "        SakayDBError,\n",
    "        lambda: sakay_db.add_trip(' Dailisan, Damian ', '09:13:00,16-08-2022',\n",
    "                                  '09:46:00,16-08-2022', 3,\n",
    "                                  ' Fairview ', ' Highway Hills', 17.6, 412)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "ff89ef34",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-03T07:38:59.074548Z",
     "start_time": "2022-09-03T07:38:58.367294Z"
    }
   },
   "outputs": [],
   "source": [
    "%%capture out\n",
    "with TemporaryDirectory() as temp_dir:\n",
    "    sakay_db = SakayDB(temp_dir)\n",
    "    shutil.copy('locations.csv', os.path.join(temp_dir, 'locations.csv'))\n",
    "    sakay_db.add_trips([\n",
    "        {'driver': 'Dailisan, Damian',\n",
    "         'pickup_datetime': '08:13:00,15-05-2022',\n",
    "         'dropoff_datetime': '08:46:00,15-05-2022',\n",
    "         'passenger_count': 2,\n",
    "         'pickup_loc_name': 'UP Campus',\n",
    "         'dropoff_loc_name': 'Legazpi Village',\n",
    "         'trip_distance': 17.6,\n",
    "         'fare_amount': 412},\n",
    "        {'driver': 'Dorosan, Michael',\n",
    "         'pickup_datetime': '14:13:00,31-12-2022',\n",
    "         'dropoff_datetime': '14:46:00,31-12-2022',\n",
    "         'passenger_count': 1,\n",
    "         'pickup_loc_name': 'Fairview',\n",
    "         'dropoff_loc_name': 'Highway Hills',\n",
    "         'trip_distance': 15.1,\n",
    "         'fare_amount': 371},\n",
    "        {'driver': 'Alis, Christian',\n",
    "         'pickup_datetime': '09:13:00,16-08-2022',\n",
    "         'dropoff_datetime': '09:46:00,16-08-2022',\n",
    "         'pickup_loc_name': 'Loyola Heights',\n",
    "         'dropoff_loc_name': 'Legazpi Village',\n",
    "         'trip_distance': 8.9,\n",
    "         'fare_amount': 235},\n",
    "        {'driver': 'Dailisan, Damian',\n",
    "         'pickup_datetime': '15:13:00,09-09-2022',\n",
    "         'dropoff_datetime': '15:46:00,09-09-2022',\n",
    "         'passenger_count': 2,\n",
    "         'pickup_loc_name': 'Pasong Putik',\n",
    "         'dropoff_loc_name': 'San Antonio',\n",
    "         'trip_distance': 31.2,\n",
    "         'fare_amount': 716},\n",
    "        {'driver': 'Dorosan, Michael',\n",
    "         'pickup_datetime': '14:13:00,31-12-2022',\n",
    "         'dropoff_datetime': '14:46:00,31-12-2022',\n",
    "         'passenger_count': 1,\n",
    "         'pickup_loc_name': 'Fairview',\n",
    "         'dropoff_loc_name': 'Highway Hills',\n",
    "         'trip_distance': 15.1,\n",
    "         'fare_amount': 371}\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "d1e49f29",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-03T07:38:59.425892Z",
     "start_time": "2022-09-03T07:38:59.420262Z"
    }
   },
   "outputs": [],
   "source": [
    "assert_equal(\n",
    "    out.stdout,\n",
    "    'Warning: trip index 2 has invalid or incomplete information. '\n",
    "    'Skipping...\\n'\n",
    "    'Warning: trip index 4 is already in the database. Skipping...\\n'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "a3d2f9a2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-03T07:39:00.557938Z",
     "start_time": "2022-09-03T07:39:00.102332Z"
    }
   },
   "outputs": [],
   "source": [
    "with TemporaryDirectory() as temp_dir:\n",
    "    sakay_db = SakayDB(temp_dir)\n",
    "    assert_raises(SakayDBError, lambda: sakay_db.generate_statistics('Trips'))\n",
    "    assert_equal(sakay_db.generate_statistics('trip'), {})\n",
    "    assert_equal(sakay_db.generate_statistics('passenger'), {})\n",
    "    assert_equal(sakay_db.generate_statistics('driver'), {})\n",
    "    assert_equal(\n",
    "        sakay_db.generate_statistics('all'),\n",
    "        {'trip': {}, 'passenger': {}, 'driver': {}}\n",
    "    )\n",
    "    shutil.copy('trips_test2.csv', os.path.join(temp_dir, 'trips.csv'))\n",
    "    shutil.copy('drivers_test2.csv',\n",
    "                os.path.join(temp_dir, 'drivers.csv'))\n",
    "    shutil.copy('locations.csv', os.path.join(temp_dir, 'locations.csv'))\n",
    "    stats_trip = sakay_db.generate_statistics('trip')\n",
    "    assert_equal(len(stats_trip), 7)\n",
    "    assert_almost_equal(stats_trip['Friday'], 41.794117647058826)\n",
    "    assert_almost_equal(stats_trip['Sunday'], 41.714285714285715)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "8eb7060d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-03T07:39:04.300357Z",
     "start_time": "2022-09-03T07:39:01.112359Z"
    }
   },
   "outputs": [],
   "source": [
    "with TemporaryDirectory() as temp_dir:\n",
    "    sakay_db = SakayDB(temp_dir)\n",
    "    shutil.copy('trips_test2.csv', os.path.join(temp_dir, 'trips.csv'))\n",
    "    shutil.copy('drivers_test2.csv',\n",
    "                os.path.join(temp_dir, 'drivers.csv'))\n",
    "    shutil.copy('locations.csv', os.path.join(temp_dir, 'locations.csv'))\n",
    "    stats_passenger = sakay_db.generate_statistics('passenger')\n",
    "    assert_equal(len(stats_passenger), 4)\n",
    "    assert_equal(len(stats_passenger[0]), 7)\n",
    "    assert_almost_equal(\n",
    "        stats_passenger[0]['Monday'],\n",
    "        9.371428571428572\n",
    "    )\n",
    "    stats_driver = sakay_db.generate_statistics('driver')\n",
    "\n",
    "    assert_equal(len(stats_driver), 200)\n",
    "    assert_almost_equal(\n",
    "        stats_driver['Dome, Benyamin']['Saturday'],\n",
    "        1\n",
    "    )\n",
    "    stats_all = sakay_db.generate_statistics('all')\n",
    "    assert_equal(set(stats_all.keys()), {'trip', 'passenger', 'driver'})\n",
    "    assert_equal(len(stats_all['trip']), 7)\n",
    "    assert_almost_equal(stats_all['trip']['Tuesday'], 39.74285714285714)\n",
    "    assert_equal(len(stats_all['passenger']), 4)\n",
    "    assert_almost_equal(stats_all['passenger'][0]['Monday'],\n",
    "                        9.371428571428572)\n",
    "    assert_almost_equal(\n",
    "        stats_all['driver']['Dome, Benyamin']['Saturday'],\n",
    "        1\n",
    "    )\n",
    "    assert_equal(len(stats_all['driver']), 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "f2c78b3f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-03T07:39:04.355237Z",
     "start_time": "2022-09-03T07:39:04.302961Z"
    }
   },
   "outputs": [],
   "source": [
    "with TemporaryDirectory() as temp_dir:\n",
    "    sakay_db = SakayDB(temp_dir)\n",
    "    assert_raises(SakayDBError, lambda: sakay_db.search_trips())\n",
    "    assert_equal(sakay_db.search_trips(driver_id=1), [])\n",
    "    shutil.copy('trips_test.csv', os.path.join(temp_dir, 'trips.csv'))\n",
    "    shutil.copy('drivers_test.csv', os.path.join(temp_dir, 'drivers.csv'))\n",
    "    assert_raises(SakayDBError, lambda: sakay_db.search_trips())\n",
    "\n",
    "    assert_equal(sakay_db.search_trips(driver_id=1).to_numpy().tolist(),\n",
    "                 [[1, 1, '08:13:00,15-05-2022', '08:46:00,15-05-2022', 2, 1, 2, 17.6, 412],\n",
    "                  [4, 1, '15:13:00,09-09-2022', '15:46:00,09-09-2022', 2, 6, 7, 31.2, 716]]\n",
    "                 )\n",
    "    assert_equal(sakay_db.search_trips(fare_amount=(None, 300)).to_numpy().tolist(),\n",
    "                 [[3, 3, '09:13:00,16-08-2022', '09:46:00,16-08-2022', 3, 5, 2, 8.9, 235]]\n",
    "                 )\n",
    "    assert_equal(sakay_db.search_trips(driver_id=1, fare_amount=(None, 300)).to_numpy().tolist(),\n",
    "                 [])\n",
    "    assert_equal(sakay_db.search_trips(driver_id=1, fare_amount=(200, 500)).to_numpy().tolist(),\n",
    "                 [[1, 1, '08:13:00,15-05-2022', '08:46:00,15-05-2022', 2, 1, 2, 17.6, 412]])\n",
    "\n",
    "    assert_equal(sakay_db.search_trips(\n",
    "                 pickup_datetime=('00:00:00,1-05-2022', '23:59:59,31-08-2022')\n",
    "                 ).to_numpy().tolist(),\n",
    "                 [[1, 1, '08:13:00,15-05-2022', '08:46:00,15-05-2022', 2, 1, 2, 17.6, 412],\n",
    "                  [3, 3, '09:13:00,16-08-2022', '09:46:00,16-08-2022', 3, 5, 2, 8.9, 235]]\n",
    "                 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "68625b75",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-03T07:39:05.483792Z",
     "start_time": "2022-09-03T07:39:04.951096Z"
    }
   },
   "outputs": [],
   "source": [
    "with TemporaryDirectory() as temp_dir:\n",
    "    sakay_db = SakayDB(temp_dir)\n",
    "    assert_equal(sakay_db.generate_odmatrix().to_numpy().tolist(), [])\n",
    "    shutil.copy('trips_test2.csv', os.path.join(temp_dir, 'trips.csv'))\n",
    "    shutil.copy('drivers_test2.csv',\n",
    "                os.path.join(temp_dir, 'drivers.csv'))\n",
    "    shutil.copy('locations.csv', os.path.join(temp_dir, 'locations.csv'))\n",
    "    od_df = sakay_db.generate_odmatrix()\n",
    "    assert_equal(od_df.shape, (48, 48))\n",
    "    assert_equal(od_df.loc['Macpherson', 'UP Campus'], 1.25)\n",
    "    assert_equal(od_df.iloc[-2, -2], 0)\n",
    "    assert_equal(sakay_db\n",
    "                   .generate_odmatrix(date_range=('00:00:00,1-08-2022', '23:59:59,31-08-2022'))\n",
    "                   .shape, (48, 48))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
